# IntervueAI Capstone

IntervueAI is an AI-powered mock interview platform that allows candidates to upload their resume and start an automated voice interview based on a given job description (JD). The system combines a FastAPI backend, a LiveKit-powered voice assistant agent, and a frontend UI built using Next.js and `pnpm`.

---

## ğŸ§± Project Structure

```
IntervueAI_Capstone/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.py                     # Main entrypoint
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml            # Model, path, port configs
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ macro_planner.py       # Subagent 1 - JD + Resume to Questionnaire
â”‚   â”œâ”€â”€ interview_loop.py      # Subagent 2 - Interview FSM Controller
â”‚   â”œâ”€â”€ scorer_summary.py      # Subagent 3 - Evaluation and summary
â”‚   â””â”€â”€ session_manager.py     # Subagent 4 - Orchestrates session lifecycle
â”œâ”€â”€ fsm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ interview_states.py    # FSM states for the main interview loop
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_service.py       # STT and TTS services (Whisper, Coqui, etc.)
â”‚   â”œâ”€â”€ llm_interface.py       # Wrapper around LLaMA model (vLLM or transformers)
â”‚   â”œâ”€â”€ vector_store.py        # Resume/JD embeddings + context memory
â”‚   â””â”€â”€ livekit_client.py      # Interface to LiveKit video/audio session control
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prompts/               # Prompt templates for each agent
â”‚   â””â”€â”€ examples/              # Sample JDs, resumes, transcripts
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ web_client/            # React/Next.js web client for LiveKit frontend
â”‚       â””â”€â”€ components/            # Chat bubbles, code editor, mic controls
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logger.py              # Unified logger
    â”œâ”€â”€ schema.py              # Dataclasses or Pydantic models for Q&A, Plan, Report
    â””â”€â”€ helpers.py             # Misc utilities
```


---

## ğŸš€ Getting Started

### ğŸ 1. Backend Setup (FastAPI)

#### ğŸ“¦ Install dependencies (recommended: virtualenv or pyenv)

```bash
pyenv virtualenv interview-agent-env
source interview-agent-env/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

#### âš™ï¸ Run FastAPI server
```
uvicorn main:app --reload --port 8000
```
FastAPI will now be running at:

```ğŸ“ http://localhost:8000```

### ğŸ¤– 2. Agent Setup (LiveKit Voice Assistant)
This agent listens in a LiveKit room and conducts the mock interview using TTS and STT.
Ensure AWS credentials are set in your .env.local or environment variables.

```
# Start the agent subprocess manually
python agents/interview_agent.py dev
```

This will load the entrypoint() function, connect to a LiveKit room, and start voice interactions when a participant joins.

### ğŸ’» 3. Frontend Setup (Next.js using pnpm)
#### ğŸ“¦ Install dependencies
```
cd ui/web_client
pnpm install
```

#### â–¶ï¸ Start the dev server

```
pnpm dev
```
Frontend will run at:
```ğŸ“ http://localhost:3000```


## ğŸ”— End-to-End Flow

1. User visits job description page â†’ clicks Apply
2. User uploads resume â†’ backend returns roomToken and serverUrl
3. User is redirected to the voice interview page using those credentials
4. LiveKit agent joins the room â†’ starts voice interview automatically

## ğŸ› ï¸ Environment Variables

Create a .env.local file for the backend and agent:

```
# .env.local
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=ap-south-1

LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret
LIVEKIT_URL=https://your-livekit-server.com
```

## ğŸ“¦ Recommended Tools

- pyenv â€” for managing Python versions
- pnpm â€” faster, disk-efficient alternative to npm
- LiveKit â€” real-time voice and video infrastructure
