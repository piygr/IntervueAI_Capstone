# IntervueAI Capstone

IntervueAI is an AI-powered mock interview platform that allows candidates to upload their resume and start an automated voice interview based on a given job description (JD). The system combines a FastAPI backend, a LiveKit-powered voice assistant agent, and a frontend UI built using Next.js and `pnpm`.

---

## ğŸ§± Project Structure

```
IntervueAI_Capstone/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.local
â”œâ”€â”€ main.py                     # Main entrypoint
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml            # Model, path, port configs
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
    â”œâ”€â”€ interview_agent.py
â”‚   â”œâ”€â”€ macro_planner.py       # tentative Subagent 1 - JD + Resume to Questionnaire
â”‚   â”œâ”€â”€ interview_loop.py      # tentative Subagent 2 - Interview FSM Controller
â”‚   â”œâ”€â”€ scorer_summary.py      # tentative Subagent 3 - Evaluation and summary
â”‚   â””â”€â”€ session_manager.py     # tentative Subagent 4 - Orchestrates session lifecycle
â”œâ”€â”€ fsm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ interview_states.py    # FSM states for the main interview loop
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_service.py       # STT and TTS services (Whisper, Coqui, etc.)
â”‚   â”œâ”€â”€ llm_interface.py       # Wrapper around LLaMA model (vLLM or transformers)
â”‚   â”œâ”€â”€ vector_store.py        # Resume/JD embeddings + context memory
â”‚   â””â”€â”€ livekit_client.py      # Interface to LiveKit video/audio session control
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prompts/               # Prompt templates for each agent
â”‚   â””â”€â”€ examples/              # Sample JDs, resumes, transcripts
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ web_client/            # React/Next.js web client for LiveKit frontend
â”‚       â””â”€â”€ components/            # Chat bubbles, code editor, mic controls
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logger.py              # Unified logger
    â”œâ”€â”€ schema.py              # Dataclasses or Pydantic models for Q&A, Plan, Report
    â””â”€â”€ helpers.py             # Misc utilities
â”‚
â”œâ”€â”€ pre_training/              # Directory containing pre-training files 
â”‚   â””â”€â”€ README.md              # Read me info specific for pretrainig part
â”‚   â”œâ”€â”€ models/            
â”‚       â””â”€â”€ llama3.py  



```


---

## ğŸš€ Getting Started

### ğŸ 1. Backend Setup (FastAPI)

#### ğŸ“¦ Install dependencies (recommended: virtualenv or pyenv)

```bash
pyenv virtualenv interview-agent-env
source interview-agent-env/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

#### âš™ï¸ Run FastAPI server
```
uvicorn main:app --reload --port 8000
```
FastAPI will now be running at:

```ğŸ“ http://localhost:8000```

### ğŸ¤– 2. Agent Setup (LiveKit Voice Assistant)
This agent listens in a LiveKit room and conducts the mock interview using TTS and STT.
Ensure AWS credentials are set in your .env.local or environment variables.

```
# Start the agent subprocess manually from the project_root directory
python -m agents.interview_agent dev
```

This will load the entrypoint() function, connect to a LiveKit room, and start voice interactions when a participant joins.

### ğŸ’» 3. Frontend Setup (Next.js using pnpm)
#### ğŸ“¦ Install dependencies
```
cd ui/web_client
pnpm install
```

#### â–¶ï¸ Start the dev server

```
pnpm dev
```
Frontend will run at:
```ğŸ“ http://localhost:3000```

### ğŸ—£ï¸ 4. LiveKit Server â€“ Local Development Setup (Optional)

This project uses [LiveKit](https://livekit.io/) to enable real-time voice communication for interview agents. You can ignore this step and
use livekit cloud by Signig up here [Livekit Cloud](https://livekit.io) 

#### ğŸ”§ Install LiveKit Server Self-hosting (locally)

##### On Mac
```
brew install livekit
```

##### On other OS
Refer here - [Livekit Server Self-hosting](https://docs.livekit.io/home/self-hosting/local/)

#### â–¶ï¸ Run LiveKit Server in Dev Mode
To start the server locally:
```
livekit-server --dev
```
This will:
- Start the server on ws://localhost:7880
- Print API_KEY and API_SECRET in your terminal (devkey / secret)
- Serve the REST API at http://localhost:7880

## ğŸ”— End-to-End Flow

1. User visits job description page â†’ clicks Apply
2. User uploads resume â†’ backend returns roomToken and serverUrl
3. User is redirected to the voice interview page using those credentials
4. LiveKit agent joins the room â†’ starts voice interview automatically

## ğŸ› ï¸ Environment Variables

Create a .env.local file for the backend and agent:

```
# .env.local
LIVEKIT_URL=ws://localhost:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret
AWS_ACCESS_KEY_ID=<aws_access_key>
AWS_SECRET_ACCESS_KEY=<aws_access_key_secret>
AWS_REGION=<aws_region>
GOOGLE_API_KEY=<google_api_key_for_running_llm>
```

## ğŸ“¦ Recommended Tools

- pyenv â€” for managing Python versions
- pnpm â€” faster, disk-efficient alternative to npm
- LiveKit â€” real-time voice and video infrastructure
