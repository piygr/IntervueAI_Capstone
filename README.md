# IntervueAI Capstone

IntervueAI is an AI-powered mock interview platform that allows candidates to upload their resume and start an automated voice interview based on a given job description (JD). The system combines a FastAPI backend, a LiveKit-powered voice assistant agent, and a frontend UI built using Next.js and `pnpm`.

## âœ… Features Implemented

### ğŸ¤ Voice-based Interview Agent
**WebRTC framework (LiveKit SDK):** Built a real-time voice-based interview system using LiveKit SDK with Python backend and React frontend.

#### Tech Stack:
- **Frontend:** React.js + LiveKit SDK
- **Backend:** FastAPI + Livekit API (Python)
- **LLM:** Gemini 2.0 Flash (Google)
- **Voice:** AWS Text-to-Speech (TTS) and Speech-to-Text (STT)


### ğŸ§  Candidate Screening Logic
**Resume Parser & JD Matching Agent:** Automatically accepts or rejects candidates before starting the interview by evaluating JD-candidate fit using vector similarity and heuristics.

### ğŸ’» Coding Interview Support
**Integrated Coding Editor:** For coding, DSA, or algorithm questions, the agent asks the candidate to open an embedded code editor to write and explain their solution.

### ğŸ”‡ Silence Handling
**Passive Listening:** Agent intelligently stays quiet if the candidate is thinking or pausing, ensuring a natural human-like experience.

**Deadlock Resolution:** If both agent and candidate are silent beyond a threshold, the agent breaks the silence with conversational nudges (e.g., â€œTake your time,â€ or â€œDo you need a hint?â€).

### ğŸ” Probing & Evaluation Logic
**Contextual Probing:** Follow-up questions are dynamically decided based on the response depth, evaluation weight of the question, and available time.

**Stuck Detection & Hints:** Agent can detect if a candidate is stuck and optionally provide contextual hints to assist progress (configurable).

### ğŸ“ Feedback Report Generation
At the end of each interview, the system generates a structured, rubric-based feedback report for the candidate â€” useful for self-evaluation and interview preparation.

### ğŸ“Š Pretraining Strategy
[Refer to the detailed README here](pre_training/README.md)

**Pretrained Foundation Model:** Llama3 1B.

**Fine-tuning:** Applied light fine-tuning on a domain-specific dataset of interview questions and candidate responses to align the model better with real-world interview patterns.

### âš ï¸ Current Challenges & Areas for Improvement

**Prompt Engineering for Custom Models:** Initial tests with local LLMs via Ollama (Phi, Mistral, etc.) didnâ€™t yield great results. Need improved prompt chaining or agent design.

**Dependency on AWS STT/TTS:** Chosen due to available credits and faster development, but may explore alternatives (e.g., Whisper, Coqui TTS) for cost scalability or latency.

**Latency and Agent Responsiveness:** Still tuning for natural response pacing and reducing perceived lag in turn-taking.

---

## ğŸ§± Project Structure

```
IntervueAI_Capstone/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.local
â”œâ”€â”€ main.py                     # Main entrypoint
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ livekit.yaml           # Needed for production setup
â”‚   â””â”€â”€ config.yaml            # Model, path, port configs
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ interview_agent.py      # Manages session and invokes coordinator agent
â”‚   â”œâ”€â”€ feedback.py             # Feedback Agent to generate
â”‚   â”œâ”€â”€ resume_pdf_parser.py    # Resume Parser Agent
â”‚   â”œâ”€â”€ jd_resume_matcher.py    # JD <-> Candidate's Resume Matcher Agent
â”‚   â”œâ”€â”€ interview_planner.py    # Interview Planner Agent
â”‚   â””â”€â”€ coordinator.py          # Coordinator Agent that Orchestrates and conducts interview

â”œâ”€â”€ prompts/                   # Prompt templates for each agent
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ web_client/            # React/Next.js web client for LiveKit frontend
â”‚       â””â”€â”€ components/        # Chat bubbles, code editor, mic controls
â””â”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ session.py             # interview session utility
â”‚   â”œâ”€â”€ memory.py              # interview conversation memory
â”‚   â””â”€â”€ llm.py                 # LLM calls utility
â”‚
â”œâ”€â”€ pre_training/              # Directory containing pre-training files 
â”‚   â””â”€â”€ README.md              # Read me info specific for pretrainig part
â”‚   â”œâ”€â”€ models/            
â”‚       â””â”€â”€ llama3.py  



```

---

## ğŸš€ Getting Started

### ğŸ 1. Backend Setup (FastAPI)

#### ğŸ“¦ Install dependencies (recommended: virtualenv or pyenv)

```bash
pyenv virtualenv interview-agent-env
source interview-agent-env/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

#### âš™ï¸ Run FastAPI server
```
uvicorn main:app --reload --port 8000
```
FastAPI will now be running at:

```ğŸ“ http://localhost:8000```

### ğŸ¤– 2. Agent Setup (LiveKit Voice Assistant)
This agent listens in a LiveKit room and conducts the mock interview using TTS and STT.
Ensure AWS credentials are set in your .env.local or environment variables.

```
# Start the agent subprocess manually from the project_root directory
python -m agents.interview_agent dev
```

This will load the entrypoint() function, connect to a LiveKit room, and start voice interactions when a participant joins.

### ğŸ’» 3. Frontend Setup (Next.js using pnpm)
#### ğŸ“¦ Install dependencies
```
cd ui/web_client
pnpm install
```

#### â–¶ï¸ Start the dev server

```
pnpm dev
```
Frontend will run at:
```ğŸ“ http://localhost:3000```

### ğŸ—£ï¸ 4. LiveKit Server â€“ Local Development Setup

This project uses [LiveKit](https://livekit.io/) to enable real-time voice communication for interview agents. You can ignore this step and
use livekit cloud (FREEMIUM) by Signig up here [Livekit Cloud](https://livekit.io) 

#### ğŸ”§ Install LiveKit Server Self-hosting (locally)

##### On Mac
```
brew install livekit
```

##### On other OS
Refer here - [Livekit Server Self-hosting](https://docs.livekit.io/home/self-hosting/local/)

#### â–¶ï¸ Run LiveKit Server in Dev Mode
To start the server locally:
```
livekit-server --dev
```
This will:
- Start the server on ws://localhost:7880
- Print API_KEY and API_SECRET in your terminal (devkey / secret)
- Serve the REST API at http://localhost:7880

## ğŸ”— End-to-End Flow

1. User visits job description page â†’ clicks Apply
2. User uploads resume â†’ backend returns roomToken and serverUrl
3. User is redirected to the voice interview page using those credentials
4. LiveKit agent joins the room â†’ starts voice interview automatically

## ğŸ› ï¸ Environment Variables

Create a .env.local file for the backend and agent:

```
# .env.local
LIVEKIT_URL=ws://localhost:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret
AWS_ACCESS_KEY_ID=<aws_access_key>
AWS_SECRET_ACCESS_KEY=<aws_access_key_secret>
AWS_REGION=<aws_region>
GOOGLE_API_KEYS=[<list_of_google_api_keys_selected_based_on_rotation]
GOOGLE_API_KEY=<google_api_key_for_running_llm>
```

## ğŸ“¦ Recommended Tools

- pyenv â€” for managing Python versions
- pnpm â€” faster, disk-efficient alternative to npm
- LiveKit â€” real-time voice and video infrastructure
